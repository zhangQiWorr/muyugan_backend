"""
æ™ºèƒ½ä½“å·¥å‚ - åŠ¨æ€åˆ›å»ºå’Œé…ç½®æ™ºèƒ½ä½“
"""
import os
from typing import Dict, List, Any
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import SystemMessage
from langgraph.prebuilt import create_react_agent
from langchain_tavily import TavilySearch

from models.agent import Agent
from services.logger import get_logger
from utils.summarization import create_summarization_hook

# è·å–factory logger
factory_logger = get_logger("factory")


class AgentFactory:
    """æ™ºèƒ½ä½“å·¥å‚"""
    
    def __init__(self):
        self.available_tools = self._load_available_tools()
        
    def _load_available_tools(self) -> Dict[str, Any]:
        """åŠ è½½å¯ç”¨å·¥å…·"""
        tools = {}
        
        @tool
        def get_weather(city: str) -> str:
            """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”é¢„æŠ¥"""
            return f"{city}çš„å¤©æ°”æ˜¯æ™´å¤©ï¼Œæ¸©åº¦é€‚å®œï¼"
        
        @tool
        def search_information(query: str) -> str:
            """æœç´¢ç›¸å…³ä¿¡æ¯"""
            return f"å…³äº '{query}' çš„æœç´¢ç»“æœï¼šè¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æœç´¢ç»“æœã€‚"
        
        @tool
        def calculate(expression: str) -> str:
            """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
            try:
                result = eval(expression)
                return f"è®¡ç®—ç»“æœ: {expression} = {result}"
            except Exception as e:
                return f"è®¡ç®—é”™è¯¯: {str(e)}"
        
        @tool
        def translate_text(text: str, target_language: str = "en") -> str:
            """ç¿»è¯‘æ–‡æœ¬"""
            return f"å°† '{text}' ç¿»è¯‘ä¸º {target_language}: [ç¿»è¯‘ç»“æœ]"
        

        @tool
        def code_analyzer(code: str, language: str = "python") -> str:
            """åˆ†æä»£ç """
            return f"ä»£ç åˆ†æç»“æœ ({language}): {code[:100]}... [åˆ†æå®Œæˆ]"
        
        tools.update({
            "weather": get_weather,
            "calculate": calculate,
            "translate": translate_text,
            "code_analyzer": code_analyzer,
            "web_search": TavilySearch()
        })
        
        return tools
    
    def create_llm(self, agent_config: Agent) -> ChatOpenAI:
        """åˆ›å»ºè¯­è¨€æ¨¡å‹å®ä¾‹"""
        
        # è·å–APIå¯†é’¥
        api_key = None
        if agent_config.api_key_name:
            api_key = os.getenv(agent_config.api_key_name)
        
        # æ ¹æ®æ¨¡å‹åç§°è®¾ç½®é»˜è®¤é…ç½®
        if "deepseek" in agent_config.model_name.lower():
            api_key = api_key or os.getenv("DEEPSEEK_API_KEY")
            base_url = agent_config.base_url or "https://api.deepseek.com"
        elif "gpt" in agent_config.model_name.lower():
            api_key = api_key or os.getenv("OPENAI_API_KEY")
            base_url = agent_config.base_url or "https://api.openai.com/v1"
        else:
            api_key = api_key or os.getenv("OPENAI_API_KEY")
            base_url = agent_config.base_url
        
        llm_config = {
            "model": agent_config.model_name,
            "temperature": agent_config.temperature,
            "max_tokens": agent_config.max_tokens,
            "top_p": agent_config.top_p,
            "frequency_penalty": agent_config.frequency_penalty,
            "presence_penalty": agent_config.presence_penalty,
            "api_key": api_key
        }
        
        if base_url:
            llm_config["base_url"] = base_url

        print(f"llm config: {llm_config} ")
        
        return ChatOpenAI(
            model= agent_config.model_name,
            base_url= llm_config["base_url"],
            api_key=llm_config["api_key"],
            temperature=llm_config["temperature"],
            max_tokens=llm_config["max_tokens"],
            top_p=agent_config.top_p,
            streaming=False,
            model_kwargs={},
            extra_body={"enable_thinking": False}
        )
    
    def get_agent_tools(self, agent_config: Agent) -> List[Any]:
        """è·å–æ™ºèƒ½ä½“å·¥å…·"""
        tools = []
        
        for tool_name in agent_config.tools_enabled:
            if tool_name in self.available_tools:
                tools.append(self.available_tools[tool_name])
        
        return tools

    def create_agent(self, agent_config: Agent, checkpointer=None) -> Any:
        """åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹"""

        # ä½¿ç”¨ä¼ å…¥çš„checkpointeræˆ–é»˜è®¤çš„checkpointer

        factory_logger.info(f"ğŸ“‹ åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹ - åç§°: {agent_config.name}, æ¨¡å‹: {agent_config.model_name}")

        try:
            # åˆ›å»ºè¯­è¨€æ¨¡å‹
            llm = self.create_llm(agent_config)

            # è·å–å·¥å…·
            tools = self.get_agent_tools(agent_config)

            # åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯
            system_message = SystemMessage(content=agent_config.system_prompt)
            
            # åˆ›å»ºæ‘˜è¦é’©å­
            pre_model_hook = create_summarization_hook(llm)

            # åˆ›å»ºååº”å¼æ™ºèƒ½ä½“ï¼Œé›†æˆæ‘˜è¦åŠŸèƒ½
            agent = create_react_agent(
                llm,
                tools,
                prompt=system_message,
                checkpointer=checkpointer,
                pre_model_hook=pre_model_hook
            )

            factory_logger.info(f"âœ… æ™ºèƒ½ä½“å®ä¾‹åˆ›å»ºæˆåŠŸï¼Œå·²é›†æˆå¯¹è¯æ‘˜è¦åŠŸèƒ½")
            return agent
            
        except Exception as e:
            factory_logger.error(f"âŒ åˆ›å»ºæ™ºèƒ½ä½“å®ä¾‹å¤±è´¥: {str(e)}")
            import traceback
            factory_logger.error(f"âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    
    def validate_agent_config(self, agent_config: Agent) -> Dict[str, Any]:
        """éªŒè¯æ™ºèƒ½ä½“é…ç½®"""
        validation_result = {
            "is_valid": True,
            "errors": [],
            "warnings": []
        }
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if not agent_config.model_name:
            validation_result["is_valid"] = False
            validation_result["errors"].append("æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
        
        if not agent_config.system_prompt:
            validation_result["is_valid"] = False
            validation_result["errors"].append("ç³»ç»Ÿæç¤ºè¯ä¸èƒ½ä¸ºç©º")
        
        # æ£€æŸ¥å‚æ•°èŒƒå›´
        if not (0.0 <= agent_config.temperature <= 2.0):
            validation_result["warnings"].append("æ¸©åº¦å‚æ•°å»ºè®®åœ¨0.0-2.0ä¹‹é—´")
        
        if agent_config.max_tokens <= 0:
            validation_result["is_valid"] = False
            validation_result["errors"].append("æœ€å¤§tokenæ•°å¿…é¡»å¤§äº0")
        
        # æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
        invalid_tools = []
        for tool_name in agent_config.tools_enabled:
            if tool_name not in self.available_tools:
                invalid_tools.append(tool_name)
        
        if invalid_tools:
            validation_result["warnings"].append(f"ä»¥ä¸‹å·¥å…·ä¸å¯ç”¨: {', '.join(invalid_tools)}")
        
        return validation_result
    
    def get_available_models(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return [
            {
                "name": "deepseek-chat",
                "display_name": "DeepSeek Chat",
                "provider": "DeepSeek",
                "description": "DeepSeekçš„å¯¹è¯æ¨¡å‹",
                "context_length": 32768,
                "capabilities": ["chat", "reasoning", "coding"]
            },
            {
                "name": "gpt-4-turbo",
                "display_name": "GPT-4 Turbo",
                "provider": "OpenAI",
                "description": "OpenAIçš„æœ€æ–°GPT-4æ¨¡å‹",
                "context_length": 128000,
                "capabilities": ["chat", "reasoning", "coding", "vision"]
            },
            {
                "name": "gpt-3.5-turbo",
                "display_name": "GPT-3.5 Turbo",
                "provider": "OpenAI",
                "description": "OpenAIçš„GPT-3.5æ¨¡å‹",
                "context_length": 16385,
                "capabilities": ["chat", "reasoning"]
            }
        ]
    
    def get_available_tools_info(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨å·¥å…·ä¿¡æ¯"""
        return [
            {
                "name": "weather",
                "display_name": "å¤©æ°”æŸ¥è¯¢",
                "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                "category": "utility"
            },
            {
                "name": "search",
                "display_name": "ä¿¡æ¯æœç´¢",
                "description": "æœç´¢ç›¸å…³ä¿¡æ¯",
                "category": "utility"
            },
            {
                "name": "calculate",
                "display_name": "æ•°å­¦è®¡ç®—",
                "description": "è¿›è¡Œæ•°å­¦è¡¨è¾¾å¼è®¡ç®—",
                "category": "productivity"
            },
            {
                "name": "translate",
                "display_name": "æ–‡æœ¬ç¿»è¯‘",
                "description": "ç¿»è¯‘æ–‡æœ¬åˆ°æŒ‡å®šè¯­è¨€",
                "category": "language"
            },
            {
                "name": "code_analyzer",
                "display_name": "ä»£ç åˆ†æ",
                "description": "åˆ†æå’Œè§£é‡Šä»£ç ",
                "category": "development"
            },
            {
                "name": "web_search",
                "display_name": "ç½‘é¡µæœç´¢",
                "description": "è”ç½‘æœç´¢",
                "category": "development"
            }
        ] 